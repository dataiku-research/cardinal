{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Active Learning Splitter\n\nActive learning experiments require heavy manipulation of indices\nfor train vs test, train being divided in labeled and unlabeled,\nlabeled being divided again in train vs validation... All those\nindex manipulation is tedious, error-prone, and can lead to repeated\nunwanted copies of data.\n\nCardinal provides a splitter easing all indices manipulation. It\nalso comes with handy procedures that make active learning\nexperiments easier.\n\n## Train vs test split\n\nThe first in an active learning experiment is to split the data\nin train and test. The training split is used to simulate the\npool of unlabeled data while the testing split is a left-out\nset of samples used to evaluate the sampler. Cardinal offers \ntwo ways of creating this split in the splitter:\n* `ActiveLearningSplitter(n_samples, test_index=[...])` allows\n  to create a splitter with no test, or by directly specifying\n  the indices.\n* `ActiveLearningSplitter.train_test_split` maps directly\n  scikit-learn's function to create the train/test split inside\n  the splitter.\n\nSee it in action below!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from cardinal.utils import ActiveLearningSplitter\nimport numpy as np\n\n\nno_test_splitter = ActiveLearningSplitter(100)\nprint('Creating a splitter without test set')\nprint('Training set size: ', no_test_splitter.train.sum())\nprint('Testing set size: ', no_test_splitter.test.sum())\nprint()\n\nwith_test_splitter = ActiveLearningSplitter(100, test_index=[10, 20, 30])\nprint('Creating a splitter with 3 test samples')\nprint('Training set size: ', with_test_splitter.train.sum())\nprint('Testing set size: ', with_test_splitter.test.sum())\nprint('Test indices: ', np.where(with_test_splitter.test)[0])\nprint()\n\nsklearn_test_splitter = ActiveLearningSplitter.train_test_split(100, test_size=20)\nprint('Creating a splitter with sklearn\\'s train_test_split')\nprint('Training set size: ', sklearn_test_splitter.train.sum())\nprint('Testing set size: ', sklearn_test_splitter.test.sum())\nprint()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sampling the first batch\n\nThe first batch of an active learning experiment is always special since\nit is not selected through the active learning procedure itself. Most works\nuse a random selection of samples for this first batch. Some work used\nan initilization through KMeans. Cardinal allows to use both of those. On\ntop of this, cardinal allows to ensure that at least one sample per class\nis selected in the random selection. This is made to prevent label addition\nduring the experiment that can be cumbersome to handle.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}